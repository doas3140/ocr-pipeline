# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/07_ocr_attention.ipynb (unless otherwise specified).

__all__ = ['read_data', 'plot', 'read_dict', 'save_dict', 'preprocess_label', 'create_lines', 'LINE_HEIGHT', 'MAIN_DIR',
           'LINES_DIR', 'PAD', 'PAD_TEST', 'printstats', 'fn2label', 'DATA_PATH', 'filenames_df', 'create_df',
           'main_df', 'char_freq', 'char_freq', 'chars', 'label_delim', 'allowed_chars', 'preprocess_string',
           'split_chars', 'fn2label_preprocessed', 'main_df', 'MultiCategoryProcessor', 'pad_idx',
           'USE_DEFAULT_CLASSES', 'MultiCategory', 'one_hot_text', 'MultiCategoryList', 'str2lines', 'MyImageList',
           'gaussian_blur', 'rand_resize', 'resize_one_img', 'train_transforms', 'valid_transforms',
           'im2seq_data_collate', 'create_data', 'conv_output', 'CRNN', 'data', 'pad_idx', 'loss_func', 'pad_idx',
           'ctc_loss', 'wer', 'word_error', 'char_error', 'decode', 'CER', 'WER']

# Cell
from fastai import *
from fastai.vision import *
import pandas as pd
import numpy as np
import cv2
from tqdm.notebook import tqdm

# Cell
def read_data(csv_path='images/X00016469670.txt'):
    ''' returns [([4,2], str),...] '''
    out = []
    with open(csv_path, encoding="utf8") as csv_file:
        csv_reader = csv.reader(csv_file, delimiter=',')
        for line in csv_reader:
            if len(line) > 8:
                x1, y1, x2, y2, x3, y3, x4, y4 = list(map(int, line[:8]))
                label = ','.join(line[8:])
                points = np.array([ [x1, y1], [x2, y2], [x3, y3], [x4, y4] ])
                out.append([points, label])
    return out

# Cell
def plot(im):
    ax = plt.figure()
    if len(im.squeeze().shape) == 2:
#         if im.max() > 1: im = im * 60
        plt.imshow(im, cmap='gray')
    else:
        plt.imshow(im)
    return plt.show()

# Cell
def read_dict(path):
    with open(path, 'rb') as handle:
        unserialized_data = pickle.load(handle)
    return unserialized_data

def save_dict(dictionary, path):
    with open(path, 'wb') as handle:
        pickle.dump(dictionary, handle, protocol=pickle.HIGHEST_PROTOCOL)

# Cell
def preprocess_label(label):
    return label.upper()

LINE_HEIGHT = 48
MAIN_DIR = '../SROIE_2019/'
LINES_DIR = os.path.join(MAIN_DIR, 'lines')
PAD = 8
PAD_TEST = 2

printstats = lambda arr, s: print(s, '| mean:', arr.mean(), 'min:', arr.min(), 'max:', arr.max())

def create_lines():
    gt_dict = {}
    total = 0
    hs, ws = [], []
    for mode in ['train', 'test']:
        filenames = os.listdir(os.path.join(MAIN_DIR, mode + '_img'))
        for fn in tqdm(filenames, total=len(filenames)):
            gt = read_data(os.path.join('../SROIE_2019/', mode + '_gt', fn[:-3] + 'txt'))
            im = cv2.imread(os.path.join('../SROIE_2019/', mode + '_img', fn[:-3] + 'jpg'))
            for i, (points, label) in enumerate(gt):
                _min, _max = np.min(points, axis=0), np.max(points, axis=0)
                if mode == 'train':
                    _min -= PAD
                    _max += PAD
                    _max[0] += 5 # pad on left so that padding would be w/out black marks
                else:
                    _min -= PAD_TEST
                    _max += PAD_TEST
                _min[0], _min[1] = max(_min[0], 0), max(_min[1], 0)
                _max[0], _max[1] = min(_max[0], im.shape[1]), min(_max[1], im.shape[0])
                im_line = im[ _min[1]:_max[1], _min[0]:_max[0] ]

                h,w,c = im_line.shape
                hs.append(h)
                ws.append(w)
                new_w = int(w * LINE_HEIGHT / float(h))
                if h < 10 or (new_w/4-2) < 1: # or len(label) == 1:
#                     plot(im)
                    plot(im_line)
#                     print(points, [label], [h,w,c])
#                     print(_min, _max, im.shape)
                    continue
#                 im_line = cv2.resize(im_line, (new_w, LINE_HEIGHT))

                line_fn = fn[:-3] + str(i) + '.jpg'
                gt_dict[line_fn] = (preprocess_label(label), mode)
                cv2.imwrite(os.path.join(LINES_DIR, 'lines', line_fn), im_line)
                total += 1
    save_dict(gt_dict, os.path.join(LINES_DIR, 'gt.pickle'))
    printstats(np.array(hs), 'height')
    printstats(np.array(ws), 'width')
    print(total)

# Cell
# NOTE: fn2label[fn] returns tuple (str(label), str(mode)), where mode = 'train'/'test'
fn2label = read_dict(os.path.join(LINES_DIR, 'gt.pickle'))
len(fn2label)

# Cell
DATA_PATH = os.path.join(LINES_DIR, 'lines')
filenames_df = pd.DataFrame(fn2label.keys(), columns=['image_path'])
filenames_df.head()

# Cell
def create_df(fn2label):
    data = []
    for fn, (label, data_split) in fn2label.items():
        data.append((fn, label, data_split == 'test'))
    return pd.DataFrame(data, columns=['image_path', 'string', 'valid'])

main_df = create_df(fn2label)
main_df.head()

# Cell
char_freq = defaultdict(lambda: 0)
for string in main_df['string']:
    for char in string:
        char_freq[char] += 1
char_freq = dict(char_freq)

# Cell
chars = [k for k in char_freq.keys()]
label_delim = '`'
label_delim in chars

# Cell
allowed_chars = set(chars + [label_delim]) - set(['·', '`'])
len(allowed_chars)

# Cell
split_chars = lambda string, delim: ''.join([char+delim for char in string])[:-1]

def preprocess_string(string):
    string = string.replace('·', '.')
    string = string.replace('`', "'")
    string = split_chars(string, label_delim)
    return string

split_chars('qwerty', label_delim)

# Cell
fn2label_preprocessed = {}
for fn, (label, data_split) in fn2label.items():
    fn2label_preprocessed[fn] = (preprocess_string(label), data_split)

main_df = create_df(fn2label_preprocessed)
main_df.head()

# Cell
# label_delim = '`' # '<pad>''
pad_idx = 0

USE_DEFAULT_CLASSES = True

class MultiCategoryProcessor(PreProcessor):
    "`PreProcessor` that create `classes` from `ds.items` and handle the mapping."
    def __init__(self, ds:ItemList):
        self.create_classes(ds.classes)
        self.use_default_classes = USE_DEFAULT_CLASSES
        self.default_classes = allowed_chars

    def create_classes(self, classes):
        self.classes = classes
        if classes is not None: self.c2i = {v:k for k,v in enumerate(classes)}

    def process_one(self,item):
        ''' list of chars from `MultiCategoryList.get()` '''
        return [ self.c2i[c] if c in self.c2i else 0 for c in item ]

    def process(self, ds):
        if self.classes is None: self.create_classes(self.generate_classes(ds.items))
        ds.classes = self.classes
        ds.c2i = self.c2i
        super().process(ds)

    def generate_classes(self, items):
        ''' items = [ ['h', 'e', 'l', 'l', 'o'], [...], ...] '''
        "Generate classes from `items` by taking the sorted unique values."
        if self.use_default_classes:
            classes = list(self.default_classes)
        else:
            classes = set()
            for c in items: classes = classes.union(set(c))
            classes = list(classes)
        classes.sort()
        return [label_delim] + classes # CHANGED

# Cell
class MultiCategory(ItemBase):
    "Basic class for multi-classification labels."
    def __init__(self, data, obj, raw): self.data, self.obj, self.raw = data, obj, raw
    def __str__(self):  return label_delim.join([str(o) for o in self.obj])
    def __hash__(self): return hash(str(self))

# Cell
def one_hot_text(x:Collection[int], c:int):
    "One-hot encode `x` with `c` classes."
    ''' x w/ len of n returns [n,c] shape arr '''
    res = np.zeros((len(x),c), np.float32)
    res[np.arange(len(x)), listify(x)] = 1.
    return res

# Cell
class MultiCategoryList(ItemList):
    "Basic `ItemList` for multi-classification labels."
    _processor = MultiCategoryProcessor
    def __init__(self, items:Iterator, classes:Collection=None, label_delim:str=None, one_hot:bool=False, **kwargs):
        self.classes = classes
        items = [line.split(label_delim) for line in items] # CHANGED
        super().__init__(items, **kwargs)
        self.processor = [MultiCategoryProcessor(self)]

    def get(self, i):
        o = self.items[i] # list of ints that represent chars
        return MultiCategory(tensor(o), [self.classes[p] for p in o], o) # CHANGED

    def analyze_pred(self, pred, thresh:float=0.5):
        return (pred >= thresh).float()

    def reconstruct(self, data_out):
        if isinstance(data_out, list): # output of data
            t_argmax, _, lengths = data_out
        else: # output from nn
#             t_argmax = torch.argmax(data_out, axis=-1) # CHANGED
            t_argmax = data_out # CHANGED
#         t = data_out[0] if isinstance(data_out, list) else data_out # if train mode it returns tuple
        ''' t [n,c] tensor '''
        o = [int(i) for i in t_argmax] # CHANGED
        return MultiCategory(one_hot_text(o, self.c), [self.classes[p] for p in o], o)

    @property
    def c(self): return len(self.classes)

# Cell
def str2lines(string, n=50):
    return ''.join([s+'\n' if (i+1)%n == 0 else s for i,s in enumerate(string)])

str2lines('asdasdasdasdasdasdasdasdasdasdasdasdasdasdasdasdasdasdasdasdasdasdasdasd')

# Cell
class MyImageList(ImageList):
    def show_xys(self, xs, ys, imgsize:int=4, figsize:Optional[Tuple[int,int]]=None, **kwargs):
        "Show the `xs` (inputs) and `ys` (targets) on a figure of `figsize`."
        rows = int(np.ceil(math.sqrt(len(xs))))
        axs = subplots(rows, 1, imgsize=imgsize, figsize=figsize) # CHANGED rows -> 1
        for x,y,ax in zip(xs, ys, axs.flatten()): x.show(ax=ax, y=y, **kwargs)
        for ax in axs.flatten()[len(xs):]: ax.axis('off')
        plt.tight_layout()

    def show_xyzs(self, xs, ys, zs, imgsize:int=20, figsize:Optional[Tuple[int,int]]=None, **kwargs):
        "Show `xs` (inputs), `ys` (targets) and `zs` (predictions) on a figure of `figsize`."
#         if self._square_show_res:
        title = 'Ground truth\nPredictions'
        rows = int(np.ceil(math.sqrt(len(xs))))
        axs = subplots(rows, 1, imgsize=imgsize, figsize=figsize, title=title, weight='bold', size=12) # CHANGED rows -> 1
        for x,y,z,ax in zip(xs,ys,zs,axs.flatten()):
            x.show(ax=ax, title=f'y_true: {str2lines(str(y))}\n\ny_pred: {str2lines(str(z))}', **kwargs)
        for ax in axs.flatten()[len(xs):]: ax.axis('off')
#         else:
#             title = 'Ground truth/Predictions'
#             axs = subplots(len(xs), 2, imgsize=imgsize, figsize=figsize, title=title, weight='bold', size=14)
#             for i,(x,y,z) in enumerate(zip(xs,ys,zs)):
#                 x.show(ax=axs[i,0], y=y, **kwargs)
#                 x.show(ax=axs[i,1], y=z, **kwargs)

# Cell
def _gaussian_blur(x, size:uniform_int):
    blurred = cv2.blur(image2np(x), (size,size)) # np.arr
#     blurred = cv2.GaussianBlur(image2np(x), (size,size), 0)
    return tensor(blurred).permute(2,0,1)

def gaussian_blur(size, p=1.0):
    return RandTransform(tfm=TfmPixel(_gaussian_blur), kwargs={'size':size}, p=p, resolved={}, do_run=True, is_random=True, use_on_y=False)

# Cell
resize_one_img = lambda x, size: F.interpolate(x[None], size=size, mode='bilinear', align_corners=True)[0]

def _rand_resize(x, pad:uniform_int):
    ''' size of subtracted padding '''
    c,h,w = x.shape
    x = x[ : , pad:h-pad , pad:w-pad ]
    new_w = int(w * LINE_HEIGHT / float(h))
    return resize_one_img(x, size=(LINE_HEIGHT, new_w))

def rand_resize(pad, p=1.0):
    return RandTransform(tfm=TfmPixel(_rand_resize), kwargs={'pad':pad}, p=p, resolved={}, do_run=True, is_random=True, use_on_y=False)

# Cell
train_transforms = [
    rand_resize(pad=(0,PAD), p=1.0),
    rotate(degrees=(-2, 2), p=0.6),
    symmetric_warp(magnitude=(-0.03, 0.03), p=0.1),
    rand_zoom(scale=(0.9,1.03), p=0.5),
    brightness(change=(0.35, 0.65), p=0.4),
    contrast(scale=(0.7,1.3), p=0.4),
    gaussian_blur(size=(1, 7), p=0.2),
#     squish(scale=(0.85,1.15), p=0.3),
    cutout(n_holes=(0,6), length=(1,10)), # black rect
#     tilt(direction=(0,3), magnitude=(-0.2,0.2), p=0.3)
]

valid_transforms = [
    rand_resize(pad=(0,0), p=1.0)
]

# Cell
def im2seq_data_collate(batch:ItemsList, pad_idx:int=0)->Tensor:
    if isinstance(batch[0][1], int): return data_collate(batch)
    "Convert `batch` items to tensor data."
    data = to_data(batch) # list of (image, text) pairs
    # image: [3,48,w], text: [n,c], where n's and w's are different
    max_w = max([image.shape[2] for image, text in data])
    max_h = max([image.shape[1] for image, text in data])
    max_n = max([text.shape[0] for image, text in data])
#     _, num_classes = data[0][1].shape

    images = torch.zeros(len(batch), 3, max_h, max_w)
#     texts = torch.zeros(len(batch), max_n, num_classes)
    texts = []
    nn_out_seq_len, texts_len = [], []
    for i, (image, text) in enumerate(data):
        c,h,w = image.shape
        images[i, : , : , :w ] = image
        images[i, : , : , w: ] = image[:,:,w-1].unsqueeze(2).expand(c,h,max_w-w)
        nn_out_seq_len.append( image_width2seq_len(w) )
        n = text.size(0)
        texts.append( tensor(text) )
#         texts[i, :n , : ] = tensor(text)
#         texts[i, n: , -1 ] = 1
        texts_len.append(n)
#     texts = torch.cat(texts, axis=0)
    return images, (texts, tensor(nn_out_seq_len).type(torch.int), tensor(texts_len).type(torch.int))

# Cell
def create_data(df, bs=32):
    ''' DataFrame (df) -> Dataloader (dl) '''
    data = (MyImageList.from_df(main_df, path=DATA_PATH, cols='image_path')
        .split_from_df(col='valid')
        .label_from_df(cols='string', label_cls=MultiCategoryList, label_delim=label_delim)
        .transform((train_transforms, valid_transforms), tfm_y=False)
        .databunch(bs=bs, collate_fn=im2seq_data_collate)
        .normalize(imagenet_stats)
    )

#     def add_beggining_and_end(b):
#         x,y = b
#         y = F.pad(y, (1, 0), value=bos_idx)
#         y = F.pad(y, (0, 1), value=eos_idx)
#         return x,y

#     data.add_tfm(add_beggining_and_end)
    return data

# Cell
def conv_output(w, ss, ps=None, ks=3):
    ''' image width, strides, pools, kernel sizes '''
    for s,p,k in zip(ss,ps,ks):
        s = s[1] if isinstance(s, tuple) else s
        w = w if w%s == 0 else w + 1
        w = (w - k + 2*p)/s + 1 if p is not None else w/s
    return int(w)

conv_output(129, [2, 1, 2, 1, (2,1), (2,1), 1], [None] * 6 + [0], [3, 3, 3, 3, 3, 3, 3])

# Cell
class CRNN(nn.Module):

    def __init__(self, nclass=10, nc=3, use_rnn=False, rnn_hidden=256, bidirectional=False):
        super(CRNN, self).__init__()
        self.nclass = nclass
        kernels = [3, 3, 3, 3, 3, 3, 3]
        strides = [2, 1, (2,1), 1, (2,1), (2,1), 1]
        channels = [64, 128, 256, 256, 512, 512, 512]
        padding = [None] * 6 + [0] # None - out size doesnt change

        self.kernels, self.strides, self.channels, self.padding = kernels, strides, channels, padding

        self.cnn = _create_cnn(kernels, strides, channels, padding)

        out_channels = channels[-1]
        self.transformer = Transformer(n_layers=6, n_heads=8, d_model=out_channels, d_inner=1024)

        self.use_rnn = use_rnn
        if self.use_rnn:
            self.rnn = nn.LSTM(out_channels, rnn_hidden, bidirectional=bidirectional)
            mult = 1 if not bidirectional else 2
            out_channels = rnn_hidden * mult

        self.out = nn.Linear(out_channels, nclass)

    def forward(self, x):
        ''' [b,c,h,w], [b,s_d] '''
        x = self.cnn(x) # [b,512,1,w/4-2]
        b, c, h, w = x.size()
        assert h == 1, "the height of conv must be 1"
        x_orig = x.squeeze(2).permute(0, 2, 1) # [b,w,512] (w == s)
        x = x_orig
        x = self.transformer(x)
        if self.use_rnn: x, _ = self.rnn(x)
        return self.out(x)

CRNN()(torch.zeros(2,3,48,128)).shape

# Cell
data = create_data(main_df, bs=16)

pad_idx = data.classes.index(label_delim)

# Cell
pad_idx = data.classes.index(label_delim)
ctc_loss = nn.CTCLoss(blank=pad_idx, reduction='mean', zero_infinity=True)

def loss_func(y_pred, y_true, y_pred_len, y_true_len):
    # y_pred: [b,s_e,c], y_true: [[s_d], [s_d], ...], lengths: [b]
    b, s_e, c = y_pred.shape
    y_true = torch.cat(y_true, axis=0) # [b*s_d]
    y_pred = y_pred.log_softmax(axis=2).permute(1,0,2) # [ s_e, b, c ]
    torch.backends.cudnn.enabled = False
    loss = ctc_loss(y_pred, y_true, y_pred_len, y_true_len)
    torch.backends.cudnn.enabled = True
    return loss

# Cell
def wer(s1,s2):
    ''' s1 - true text, s2 - pred text '''
    d = np.zeros([len(s1)+1,len(s2)+1])
    d[:,0] = np.arange(len(s1)+1)
    d[0,:] = np.arange(len(s2)+1)

    for j in range(1,len(s2)+1):
        for i in range(1,len(s1)+1):
            if s1[i-1] == s2[j-1]:
                d[i,j] = d[i-1,j-1]
            else:
                d[i,j] = min(d[i-1,j]+1, d[i,j-1]+1, d[i-1,j-1]+1)

    return d[-1,-1]/len(s1)

word_error = wer( 'black frog jumped away'.split(' '), 'black frog jumped awayyy'.split(' ') )
char_error = wer( 'black frog jumped away', 'black frog jumped awayyy' )
char_error, word_error

# Cell
def decode(texts, classes=data.classes):
    """ convert text-index into text-label. (make sure len(t) doesnt throw length of 0-dim error) """
    out = []
    index = 0
    for t in texts:
        char_list = []
        for i in range(len(t)):
            if t[i] != 0 and (not (i > 0 and t[i - 1] == t[i])):  # removing repeated characters and blank.
                char_list.append(t[i])
#         text = ''.join(char_list)

        out.append(tensor(char_list))
    return out

# Cell
def CER(y_pred, y_true, y_pred_len, y_true_len):
    # y_pred: [b,s_e,c], y_true: [[s_d], [s_d], ...], lengths: [b]
    y_pred = y_pred.argmax(-1)
    y_pred = decode(y_pred)
    m = 0
    for yp, p_len, yt in zip(y_pred, y_pred_len, y_true):
        if yp.shape == torch.Size([]): continue
        yt_text = ''.join([learner.data.classes[i] for i in yt])
        yp_text = ''.join([learner.data.classes[i] for i in yp])
        m += wer(yt_text, yp_text)
    return tensor(m / len(y_pred))

#export
def WER(y_pred, y_true, y_pred_len, y_true_len):
    # y_pred: [b,s_e,c], y_true: [[s_d], [s_d], ...], lengths: [b]
    y_pred = y_pred.argmax(-1)
    y_pred = decode(y_pred)
    m = 0
    for yp, p_len, yt in zip(y_pred, y_pred_len, y_true):
        if yp.shape == torch.Size([]): continue
        yt_text = ''.join([learner.data.classes[i] for i in yt])
        yp_text = ''.join([learner.data.classes[i] for i in yp])
        m += wer(yt_text.split(' '), yp_text.split(' '))
    return tensor(m / len(y_pred))