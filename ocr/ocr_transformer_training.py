# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/08_ocr_transformer_training.ipynb (unless otherwise specified).

__all__ = ['PAD', 'PAD', 'transformer_config', 'allowed_chars', 'allowed_fonts', 'TextlineProcessor', 'label_delim',
           'eos', 'bos', 'pad_idx', 'bos_idx', 'eos_idx', 'TextlineAndFont', 'TextlineList', 'train_transforms',
           'valid_transforms', 'im2seq_data_collate', 'create_data', 'conv_output', 'MultiHeadAttention',
           'feed_forward', 'EncoderBlock', 'DecoderBlock', 'get_output_mask', 'PositionalEncoding',
           'TransformerEmbedding', 'compose', 'Transformer', 'CNN', 'RevConv', 'get_normal_cnn',
           'get_partially_rev_cnn', 'TransformerModel', 'TextFontLoss', 'word_error', 'char_error',
           'decode_single_transformer_output', 'decode_transformer_output', 'TransformerWordErrorRate']

# Cell
from fastai import *
from fastai.vision import *
import pandas as pd
import numpy as np
import cv2
from tqdm.notebook import tqdm

# Cell
from .core import save_inference, load_inference
from .ocr_dataset_fontsynth import create_df as create_fontsynth_df
from .ocr_dataset_sroie2019 import create_df as create_sroie_df
from .ocr_dataset_brno import create_df as create_brno_df
from .ocr_dataset_sroie2019 import sroie_ocr_config, char_freq
from .ocr_dataset_fontsynth import fontsynth_config, char_freq
from .ocr_dataset_brno import brno_ocr_config
PAD = sroie_ocr_config.PAD # PAD - how much is data padded
PAD = 0

# Cell
allowed_chars = {'L', '*', ':', ' ', 'C', '.', 'D', '%', '-', '"', 'J', '[', ']', 'H', '1', '<', '@',
                 'W', 'K', '+', 'Y', '7', '?', 'T', '5', '!', '#', 'P', '&', 'U', '$', 'G', ';', '~', "'",
                 ')', 'V', '_', 'O', ',', '/', 'Q', '0', '4', 'B', '=', '9', '8', '3', '>', '6', 'Z', '\\',
                 'F', 'X', 'R', 'I', 'E', 'S', '|', '{', '^', 'A', '}', '2', 'M', 'N', '('}

# allowed_chars = fontsynth_config.allowed_chars

allowed_fonts = ['Unknown', 'Andale_Mono', 'Arial', 'Arial_Black', 'Arial_Bold', 'Arial_Bold_Italic', 'Arial_Italic',
'Comic_Sans_MS_Bold', 'Courier_New', 'Courier_New_Bold', 'Courier_New_Bold_Italic', 'Courier_New_Italic',
'Georgia', 'Georgia_Bold', 'Georgia_Bold_Italic', 'Georgia_Italic', 'Impact', 'Times_New_Roman',
'Times_New_Roman_Bold', 'Times_New_Roman_Bold_Italic', 'Times_New_Roman_Italic', 'Trebuchet_MS',
'Trebuchet_MS_Bold', 'Trebuchet_MS_Bold_Italic', 'Trebuchet_MS_Italic', 'Verdana', 'Verdana_Bold',
'Verdana_Bold_Italic', 'Verdana_Italic', 'brno_easy', 'brno_medium', 'sroie2019', 'Comic_Sans_MS']

class transformer_config:
    LINE_HEIGHT = 48
    USE_DEFAULT_CLASSES = True
    eos = '</s>'
    bos = '<s>'
    label_delim = '`' # will used as padding here
    pad_idx = 0
    bos_idx = 1
    eos_idx = 2
    allowed_chars = allowed_chars
    allowed_fonts = allowed_fonts

# Cell
from .ocr_crnn_training import TextlineProcessor, TextlineAndFont, TextlineList, MyImageList, im2seq_data_collate
from .ocr_crnn_training import one_hot_text, decode_single_ctc, decode_ctc, gaussian_blur, rand_resize

# Cell
label_delim = transformer_config.label_delim
eos = transformer_config.eos
bos = transformer_config.bos

pad_idx = transformer_config.pad_idx
bos_idx = transformer_config.bos_idx
eos_idx = transformer_config.eos_idx

class TextlineProcessor(TextlineProcessor):
    def __init__(self, ds:ItemList):
        self.create_classes(ds.classes, ds.font_classes)
        self.use_default_classes = transformer_config.USE_DEFAULT_CLASSES
        self.default_classes = transformer_config.allowed_chars
        self.default_font_classes = transformer_config.allowed_fonts

    def process_one(self,item):
        chars, fontidx = super().process_one(item)
        return [bos_idx] + chars + [eos_idx], fontidx

    def create_classes(self, classes, font_classes):
        self.classes, self.font_classes = classes, font_classes
        if classes is not None:
            self.classes = [label_delim, bos, eos] + classes
            self.c2i = {v:k for k,v in enumerate(self.classes)}
            self.f2i = {v:k for k,v in enumerate(font_classes)}

# Cell
class TextlineAndFont(ItemBase):
    ''' F = font, S = string
    data: tensor(S), tensor(F)
    obj: str(S), str(F)
    raw: str(S), list(F)
    '''
    def __init__(self, data, obj, raw):self.data, self.obj, self.raw = data, obj, raw
    def __str__(self, n=20):
        string = self.obj[0][:n]+['...'] if len(self.obj[0]) > n else self.obj[0]
        return self.obj[1][:5] +'...'+ transformer_config.label_delim.join([str(o) for o in string])
    def __hash__(self): return hash(str(self))

# Cell
class TextlineList(ItemList):
    _processor = TextlineProcessor
    def __init__(self, items:Iterator, classes=None, font_classes=None, label_delim:str=None, one_hot:bool=False, **kwargs):
        self.classes = classes
        self.font_classes = font_classes
        items = [(string.split(transformer_config.label_delim),font) for string,font in items] # CHANGED
        super().__init__(items, **kwargs)
        self.processor = [TextlineProcessor(self)]

    def get(self, i):
        stridxs, fontidx = self.items[i] # int, list of ints
        return TextlineAndFont( (tensor(stridxs), tensor(fontidx)),
                                ([self.classes[c] for c in stridxs], self.font_classes[fontidx]), self.items[i])

    # no need analyze pred, cuz we wont use learner.show_results

    def reconstruct(self, data_out):
        fontidx, t_argmax = data_out # output from data / output from nn_out -> analyze_pred
        stridxs = [int(i) for i in t_argmax]
        fontidx = int(fontidx)
        return TextlineAndFont((one_hot_text(stridxs, self.c), fontidx),
                                ([self.classes[c] for c in stridxs], self.font_classes[fontidx]), data_out)

    @property
    def c(self): return len(self.classes)

# Cell
train_transforms = [
    rand_resize(pad=(0,PAD), p=1.0),
    rotate(degrees=(-2, 2), p=0.6),
    symmetric_warp(magnitude=(-0.03, 0.03), p=0.3),
    rand_zoom(scale=(0.9,1.03), p=0.5),
    brightness(change=(0.35, 0.65), p=0.4),
    contrast(scale=(0.7,1.3), p=0.4),
    gaussian_blur(size=(1, 7), p=0.2),
#     squish(scale=(0.85,1.15), p=0.3),
#     cutout(n_holes=(0,6), length=(1,10)), # black rect
#     tilt(direction=(0,3), magnitude=(-0.2,0.2), p=0.3)
]

valid_transforms = [
    rand_resize(pad=(0,0), p=1.0) # (no padding, but need to resize)
]

# Cell
def im2seq_data_collate(batch, text_pad_idx=pad_idx):
    "Function that collect samples and adds padding. Flips token order if needed"
    if len(batch) == 1: return data_collate(batch)
    data = to_data(batch) # list of (image, text) pairs
    # image: [3,48,w], text: [n], where n's and w's are different
    max_w = max([image.shape[2] for image, (text,font) in data])
    max_h = max([image.shape[1] for image, (text,font) in data])
    max_n = max([text.shape[0] for image, (text,font) in data])
    # results
    fonts = torch.zeros(len(batch)).long()
    res_x = torch.zeros(len(batch), 3, max_h, max_w)
    res_y = torch.zeros(len(batch), max_n).long() + text_pad_idx
    for i, (image, (text,font)) in enumerate(data):
        fonts[i] = font
        c,h,w = image.shape
        res_x[i, : , : , :w ] = image
        res_x[i, : , : , w: ] = image[:,:,w-1].unsqueeze(2).expand(c,h,max_w-w)
        res_y[i, :len(text) ] = LongTensor(text)
    return res_x, (fonts, res_y)

# Cell
def create_data(df, bs=32):
    ''' DataFrame (df) -> Dataloader (dl) '''
    data = (MyImageList.from_df(df, path='.', cols='image_path')
        .split_from_df(col='valid')
        .label_from_df(cols='string', label_cls=TextlineList, label_delim=label_delim)
        .transform((train_transforms, valid_transforms), tfm_y=False)
        .databunch(bs=bs, collate_fn=im2seq_data_collate)
        .normalize()
    )
#     data.train_dl.numworkers=0
#     data.valid_dl.numworkers=0
    return data

# Cell
def conv_output(w, ss, ps=None, ks=3):
    ''' image width, strides, pools, kernel sizes '''
    for s,p,k in zip(ss,ps,ks):
        s = s[1] if isinstance(s, tuple) else s
        w = w if w%s == 0 else w + 1
        w = (w - k + 2*p)/s + 1 if p is not None else w/s
    return int(w)

conv_output(129, [2, 1, 2, 1, (2,1), (2,1), 1], [None] * 6 + [0], [3, 3, 3, 3, 3, 3, 3])

# Cell
_apply_layer = lambda args: args[1](args[0]) # args[0]: x, args[1]: layer => layer(x)

class MultiHeadAttention(nn.Module):
    def __init__(self, n_heads, d_model, d_head=None, p=0., bias=True, scale=True, shared_qk=False):
        super().__init__()
        d_head = ifnone(d_head, d_model//n_heads)
        self.n_heads,self.d_head,self.scale = n_heads,d_head,scale
        self.q_wgt, self.v_wgt = [nn.Linear(d_model, n_heads*d_head, bias=bias) for o in range(2)]
        self.k_wgt = self.q_wgt if shared_qk else nn.Linear(d_model, n_heads*d_head, bias=bias)
        self.out = nn.Linear(n_heads * d_head, d_model, bias=bias)
        self.drop_att,self.drop_res = nn.Dropout(p),nn.Dropout(p)
        self.ln = nn.LayerNorm(d_model)

    def forward(self, q, kv, mask=None):
        ''' [b,s_d,512], [b,s_e,512], [1,1,s_d,s_e] -> [b,s_d,512] '''
        bs,seq_len = q.size(0),q.size(1)
        wq,wk,wv = map(_apply_layer, zip([q,kv,kv], [self.q_wgt,self.k_wgt,self.v_wgt])) # [b,s_d,h*512], [b,s_e,h*512] x 2
        wq,wk,wv = map(lambda x:x.view(bs, x.size(1), self.n_heads, self.d_head), (wq,wk,wv)) # [b,s_d,h,512], [b,s_e,h,512] x 2
        wq,wv = map(lambda x:x.permute(0, 2, 1, 3), (wq,wv)) # [b,h,s_d,512], [b,h,s_e,512]
        wk = wk.permute(0, 2, 3, 1) # [b,h,512,s_e]
        attn_score = torch.matmul(wq, wk) # [b,h,s_d,s_e]
        if self.scale: attn_score.div_(self.d_head ** 0.5)
        if mask is not None: # NOTE: masks only ones, not zeros!
            attn_score = attn_score.float().masked_fill(mask, -float('inf')).type_as(attn_score) # [b,h,s_d,s_e]
        attn_prob = self.drop_att(F.softmax(attn_score, dim=-1)) # [b,h,s_d,s_e]
        attn_vec = torch.matmul(attn_prob, wv) # [b,h,s_d,512]
        attn_vec = attn_vec.permute(0, 2, 1, 3).contiguous().contiguous() # [b,s_d,h,512]
        attention = attn_vec.view(bs, seq_len, -1) # [b,s_d,h*512]
        return self.ln(q + self.drop_res(self.out(attention)))

# Cell
def feed_forward(d_model:int, d_ff:int, ff_p:float=0., activ_func=partial(nn.ReLU, inplace=True), double_drop:bool=True):
    ''' [...,d] -> [...,d] '''
    layers = [nn.Linear(d_model, d_ff), activ_func()]
    if double_drop: layers.append(nn.Dropout(ff_p))
    return SequentialEx(*layers, nn.Linear(d_ff, d_model), nn.Dropout(ff_p), MergeLayer(), nn.LayerNorm(d_model))

# Cell
class EncoderBlock(nn.Module):
    "Encoder block of a Transformer model."
    def __init__(self, n_heads, d_model, d_inner, p=0., bias=True, scale=True, double_drop=True):
        super().__init__()
        self.mha = MultiHeadAttention(n_heads, d_model, p=p, bias=bias, scale=scale)
        self.ff  = feed_forward(d_model, d_inner, ff_p=p, double_drop=double_drop)

    def forward(self, x, mask=None):
        ''' [b,s_e,512], [1,1,s_e,s_e] -> [b,s_e,512] '''
        return self.ff(self.mha(x, x, mask=mask))

# Cell
class DecoderBlock(nn.Module):
    "Decoder block of a Transformer model."
    def __init__(self, n_heads, d_model, d_inner, p=0., bias=True, scale=True, double_drop=True):
        super().__init__()
        self.mha1 = MultiHeadAttention(n_heads, d_model, p=p, bias=bias, scale=scale)
        self.mha2 = MultiHeadAttention(n_heads, d_model, p=p, bias=bias, scale=scale)
        self.ff   = feed_forward(d_model, d_inner, ff_p=p, double_drop=double_drop)

    def forward(self, x, enc, mask_out=None):
        ''' [b,s_d,512], [b,s_e,512], [1,1,s_d,s_d] -> [b,s_d,512] '''
        return self.ff(self.mha2(self.mha1(x, x, mask_out), enc))

# Cell
def get_output_mask(inp, pad_idx=1):
    ''' [b,s_e,...] -> [1,1,s_e,s_e] '''
    return torch.triu(inp.new_ones(inp.size(1),inp.size(1)), diagonal=1)[None,None].type(torch.bool)

# Cell
class PositionalEncoding(Module):
    "Encode the position with a sinusoid."
    def __init__(self, d:int): self.register_buffer('freq', 1 / (10000 ** (torch.arange(0., d, 2.)/d)))

    def forward(self, pos:Tensor):
        inp = torch.ger(pos, self.freq)
        enc = torch.cat([inp.sin(), inp.cos()], dim=-1)
        return enc

# Cell
class TransformerEmbedding(nn.Module):
    "Embedding + positional encoding + dropout"
    def __init__(self, emb_sz, vocab_sz=None, drop=0.):
        super().__init__()
        self.emb_sz = emb_sz
        if vocab_sz is None: self.embed = None
        else: self.embed = nn.Embedding(vocab_sz, emb_sz)
        self.pos_enc = PositionalEncoding(emb_sz)
        self.drop = nn.Dropout(drop)
        self.alpha = nn.Parameter(tensor(1.))

    def forward(self, inp):
        ''' [] -> [] '''
        pos = torch.arange(0, inp.size(1), device=inp.device).float()
        if self.embed is not None: inp = self.embed(inp)
        return self.drop(inp + self.alpha * self.pos_enc(pos))
#         return self.drop(self.embed(inp) * math.sqrt(self.emb_sz) + self.pos_enc(pos))

# Cell
def compose(funcs):
    def func_out(x, *args):
        for f in listify(funcs):
            x = f(x, *args)
        return x
    return func_out

# Cell
class Transformer(Module):
    def __init__(self, out_vsz, n_layers=6, n_heads=8, d_model=512, d_inner=1024, p=0.1,
                 bias=True, scale=True, double_drop=True, pad_idx=1, one_hot_encoded=False):
        self.enc_emb = TransformerEmbedding(d_model, drop=0.05)
        self.dec_emb = TransformerEmbedding(d_model, vocab_sz=out_vsz, drop=0.1)
#         self.dec_emb = PositionalEncoding(d_model)
        args = (n_heads, d_model, d_inner, p, bias, scale, double_drop)
        self.encoders = nn.ModuleList([EncoderBlock(*args) for _ in range(n_layers)])
        self.decoders = nn.ModuleList([DecoderBlock(*args) for _ in range(n_layers)])
#         self.out = nn.Linear(d_model, out_vsz)
        # self.out.weight = self.dec_emb.embed.weight
        self.pad_idx = pad_idx
        self.one_hot_encoded = one_hot_encoded

    def forward(self, inp, out):
        ''' [b,s_e,512], [b,s_d,c] or [b,s_d] -> [b,s_d,c] (c - num classes) '''
        if self.one_hot_encoded: out = out.argmax(-1) # [b,s_d]
        mask_out = get_output_mask(out, self.pad_idx) # [1,1,s_d,s_d]
#         out = self.dec_emb(torch.zeros_like(out))
        out = self.dec_emb(out)
        enc = self.enc_emb(inp) #
        enc = compose(self.encoders)(enc) # [b,s_e,512]
        out = compose(self.decoders)(out, enc, mask_out) # [b,s_d,512]
        return out

# Cell
class CNN(nn.Module):
    def __init__(self, d_model, cnn_layers, kernels, strides, channels, padding, nc=3):
        super().__init__()
        layers = []
        for layer,i,o,k,s,p in zip(cnn_layers, [nc] + channels[:-1], channels, kernels, strides, padding):
            layers.append( layer(ni=i, nf=o, ks=k, stride=s, padding=p) )
        self.cnn = nn.Sequential(*layers)
        b,c,h,w = self.cnn(torch.zeros(1,3,48,128)).shape
        self.out = nn.Linear(h*c, d_model)
        print('CNN output = h:{} c:{}'.format(h,c))

    def forward(self, x):
        x = self.cnn(x).permute(0,3,1,2)
        b,w,c,h = x.shape
        return self.out(x.view(b,w,-1)) # [b,c,h,w]

# Cell
import revtorch as rv

def RevConv(ni, nf, ks, stride, padding):
    assert ni == nf and stride == 1
    f_func = conv_layer(ni//2, nf//2, ks, stride=stride, padding=padding)
    g_func = conv_layer(ni//2, nf//2, ks, stride=stride, padding=padding)
    layers = nn.ModuleList([rv.ReversibleBlock(f_func, g_func)])
    return rv.ReversibleSequence(layers, eagerly_discard_variables = True)

# Cell
def get_normal_cnn(dx=1):
    strides = [2, 1, (2,1), 1, (2,1), 1, (2,1), 1]
    channels = [int(c*dx) for c in [64, 64, 128, 128, 256, 256, 512, 512]]
    cnn_layers = [conv_layer] * len(strides)
    kernels = [3] * len(strides)
    padding = [None] * len(strides) # None - out size doesnt change
    return cnn_layers, channels, kernels, strides, padding

# Cell
def get_partially_rev_cnn(dx=1):
    strides = [2, 1, (2,1), 1, (2,1), 1, (2,1), 1]
    channels = [int(c*dx) for c in [64, 64, 128, 128, 256, 256, 512, 512]]
    cnn_layers = [conv_layer, RevConv] * (len(strides)//2)
    kernels = [3] * len(strides)
    padding = [None] * len(strides) # None - out size doesnt change
    return cnn_layers, channels, kernels, strides, padding

# Cell
class TransformerModel(nn.Module):

    def __init__(self, nclass=10, fclass=10, nc=3, n_layers=6, d_model=512, d_ff=1024):
        super().__init__()

        cnn_layers, self.channels, self.kernels, self.strides, self.padding = get_partially_rev_cnn(dx=1/2)
        self.cnn = CNN(d_model, cnn_layers, self.kernels, self.strides, self.channels, self.padding, nc=nc)

        # font prediction
        h,w = 2,d_model
        self.adaptive_pool = nn.AdaptiveAvgPool2d([h,w]) # this([h,w])([B,H,W]) -> [B,h,w]
        f_model = 2 # font embedding
        self.font_ff = nn.Sequential(nn.Linear(h*w, fclass*f_model), nn.ReLU())
        self.font_out = nn.Linear(f_model, 1)

        # font embedding x text attention
        self.font_emb = nn.Linear(f_model, d_model)
        self.font_attention = DecoderBlock(n_heads=8, d_model=d_model, d_inner=d_ff)

        # text prediction
        self.transformer = Transformer(nclass, n_layers=n_layers, n_heads=8, d_model=d_model, d_inner=d_ff)
        self.out = nn.Linear(d_model, nclass)

        self.nclass, self.d_model, self.fclass, self.f_model = nclass, d_model, fclass, f_model

    def encode_images(self, x):
        b,c,h,w = x.shape
        x = self.cnn(x) # [b,s_e,512]
        f = self.adaptive_pool(x).view(b,-1) # [b,h_a x w_a] (_a = adaptive pool params)
        f_enc = self.font_ff(f).view(-1, self.fclass, self.f_model)
        f_out = self.font_out(f_enc).view(-1, self.fclass)
        f_emb = self.font_emb(f_enc) # [b,f,512]
        return x, f_out, f_emb

    def decode(self, x_enc, y_input, f_emb=None):
        x = self.transformer(x_enc, y_input) # [b,s_d,c]
        if f_emb is not None: x = self.font_attention(x=x, enc=f_emb) # [b,s_d,c]
        return self.out(x)

    def forward(self, x, y_input):
        ''' [b,c,h,w], [b,s_d] '''
        x_enc, f_out, f_emb = self.encode_images(x)
        y_pred = self.decode(x_enc, y_input)
        return f_out, y_pred

# Cell
class TextFontLoss(nn.Module):
    def __init__(self, text_pad_idx=pad_idx):
        super().__init__()
        self.pad_idx = text_pad_idx
        self.metric_names = ['text_loss', 'font_loss']

    def _text_loss(self, y_pred, y_true):
        mask = y_true != self.pad_idx
        return CrossEntropyFlat()(y_pred[mask], y_true[mask])

    def _font_loss(self, y_pred, y_true):
        return CrossEntropyFlat()(y_pred, y_true)

    def forward(self, nn_output, font_true, y_true):
        font_pred, y_pred = nn_output
        text = self._text_loss(y_pred, y_true)
        font = self._font_loss(font_pred, font_true)
        self.metrics = dict(zip(self.metric_names, [text, font]))
        return text + font

# Cell
from .ocr_crnn_training import wer, AddLossMetrics, WordErrorRate

word_error = wer( 'black frog jumped away'.split(' '), 'black frog jumped awayyy'.split(' ') )
char_error = wer( 'black frog jumped away', 'black frog jumped awayyy' )
char_error, word_error

# Cell
def decode_single_transformer_output(char_idxes, eos_idx, pad_idx=pad_idx):
    char_list = []
    for i in char_idxes:
        if i != pad_idx: char_list.append(i)
        if i == eos_idx: break
    return char_list[1:-1]

def decode_transformer_output(texts, eos_idx=eos_idx):
    return [tensor(decode_single_transformer_output(t, eos_idx=eos_idx)) for t in texts]

# Cell
class TransformerWordErrorRate(WordErrorRate):
    def __init__(self, learner, eos_idx=eos_idx):
        decode_func = partial(decode_transformer_output, eos_idx=eos_idx)
        return super().__init__(learner, decode_func, decode_func)

    def on_batch_end(self, last_output, last_target, train, **kwargs):
        if train: return
        font_pred, y_pred = last_output
        font_true, y_true = last_target
        y_pred = y_pred.argmax(-1)
        y_pred = self.decode_pred(y_pred)
        y_true = self.decode_true(y_true)
        for yp, yt in zip(y_pred, y_true):
            self.total += 1
            if yp.shape == torch.Size([]): continue
            yt_text = ''.join([self.classes[i] for i in yt]) # w/out bos
            yp_text = ''.join([self.classes[i] for i in yp]) # w/out bos and eos
            print([yt_text], yp_text)
            self.wer += wer(yt_text.split(' '), yp_text.split(' '))
            self.cer += wer(yt_text, yp_text)